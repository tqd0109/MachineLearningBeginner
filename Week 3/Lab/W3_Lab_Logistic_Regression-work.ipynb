{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 - Lab - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "![Imgur](https://i.imgur.com/UB4Kg0w.jpg)\n",
    "[Link to sketchboard](https://sketchboard.me/tBjCwrhXsFwu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Confusion Matrices\n",
    "\n",
    "https://towardsdatascience.com/taking-the-confusion-out-of-confusion-matrices-c1ce054b3d3e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy, pandas\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We use 2 models to predict if a woman is pregnant or not and save the result in \"pregnant.csv\" files.\n",
    "* pregnent dataset has 3 columns:\n",
    "    * Actual is actual result (ground truth)\n",
    "    * model_1_predict, model_2_predict are prediction results from model 1 and model 2\n",
    "\n",
    "**Now, we have to answer the question which model is better?**\n",
    "\n",
    "First of all, let's load dataset and print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>model_1_predict</th>\n",
       "      <th>model_2_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  model_1_predict  model_2_predict\n",
       "0       0                0                0\n",
       "1       1                0                1\n",
       "2       0                0                0\n",
       "3       0                0                0\n",
       "4       0                0                0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pregnant = pd.read_csv('./pregnant.csv')\n",
    "df_pregnant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 3 columns):\n",
      "Actual             500 non-null int64\n",
      "model_1_predict    500 non-null int64\n",
      "model_2_predict    500 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 11.8 KB\n"
     ]
    }
   ],
   "source": [
    "df_pregnant.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>model_1_predict</th>\n",
       "      <th>model_2_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.3003</td>\n",
       "      <td>0.407716</td>\n",
       "      <td>0.400401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Actual  model_1_predict  model_2_predict\n",
       "count  500.0000       500.000000       500.000000\n",
       "mean     0.1000         0.210000         0.200000\n",
       "std      0.3003         0.407716         0.400401\n",
       "min      0.0000         0.000000         0.000000\n",
       "25%      0.0000         0.000000         0.000000\n",
       "50%      0.0000         0.000000         0.000000\n",
       "75%      0.0000         0.000000         0.000000\n",
       "max      1.0000         1.000000         1.000000"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pregnant.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate True Positive, False Positive, True Negative, False Negative of model 1\n",
    "![Alt](https://cdn-images-1.medium.com/max/800/1*g5zpskPaxO8uSl0OWT4NTQ.png)\n",
    "Note\n",
    "* Positive : 1(Pregnant)\n",
    "* Negative : 0(Not Pregnant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Positive : Predict **Positive** and it's **True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Positive\n",
    "positive = df_pregnant['model_1_predict'] == 1\n",
    "correct_predict = df_pregnant['model_1_predict'] == df_pregnant['Actual']\n",
    "\n",
    "TP = sum(positive & correct_predict)\n",
    "TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Positive: Predict **Positive** and it's **False**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Positive\n",
    "positive = df_pregnant['model_1_predict'] == 1\n",
    "incorrect_predict = df_pregnant['model_1_predict'] != df_pregnant['Actual']\n",
    "\n",
    "FP = sum(positive & incorrect_predict)\n",
    "FP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Negative : Predict **Negative** and it's **True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Negative\n",
    "negative = df_pregnant['model_1_predict'] == 0\n",
    "correct_predict = df_pregnant['model_1_predict'] == df_pregnant['Actual']\n",
    "\n",
    "TN = sum(negative & correct_predict)\n",
    "TN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Negative: Predict **Negative** and it's **False**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Negative\n",
    "negative = df_pregnant['model_1_predict'] == 0\n",
    "incorrect_predict = df_pregnant['model_1_predict'] != df_pregnant['Actual']\n",
    "\n",
    "FN = sum(negative & incorrect_predict)\n",
    "FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs Precision vs Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt img](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/440px-Precisionrecall.svg.png)\n",
    "\n",
    "- Accuracy (all correct / all) = (TP + TN) / (TP + TN + FP + FN)\n",
    "- Precision (true positives / predicted positives) = TP / (TP + FP)\n",
    "- Sensitivity aka Recall (true positives / all actual positives) = TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.85\n",
      "Precision:  0.38095238095238093\n",
      "RecalL   :  0.8\n"
     ]
    }
   ],
   "source": [
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Precision = TP / (TP + FP)\n",
    "Recall = TP / (TP + FN)\n",
    "print(\"Accuracy : \", Accuracy)\n",
    "print(\"Precision: \", Precision)\n",
    "print(\"RecalL   : \", Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank to Sklearn for making our life more easier with classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[385  65]\n",
      " [ 10  40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91       450\n",
      "           1       0.38      0.80      0.52        50\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       500\n",
      "   macro avg       0.68      0.83      0.71       500\n",
      "weighted avg       0.92      0.85      0.87       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(df_pregnant['Actual'], df_pregnant['model_1_predict'])\n",
    "report = classification_report(df_pregnant['Actual'], df_pregnant['model_1_predict'])\n",
    "print(confusion)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[395  55]\n",
      " [  5  45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       450\n",
      "           1       0.45      0.90      0.60        50\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       500\n",
      "   macro avg       0.72      0.89      0.76       500\n",
      "weighted avg       0.93      0.88      0.90       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply the same with model 2\n",
    "confusion = confusion_matrix(df_pregnant['Actual'], df_pregnant['model_2_predict'])\n",
    "report = classification_report(df_pregnant['Actual'], df_pregnant['model_2_predict'])\n",
    "print(confusion)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentiment analysis\n",
    "\n",
    "This contest is taken from the real task of Text Processing.\n",
    "\n",
    "The task is to build a model that will determine the tone (positive, negative) of the text. To do this, you will need to train the model on the existing data (train.csv). The resulting model will have to determine the class (neutral, positive, negative) of new texts. The dataset contains the following fields:\n",
    "\n",
    "| Field name | Meaning |\n",
    "|------------|-----------|\n",
    "| ItemID  | id of twit|\n",
    "| Sentiment | sentiment (1-positive, 0-negative)|\n",
    "| SentimentText | text of the twit|\n",
    "\n",
    "Let's first of all have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25928</th>\n",
       "      <td>25940</td>\n",
       "      <td>0</td>\n",
       "      <td>@adil320 sending you hugs and encouragment tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39572</th>\n",
       "      <td>39584</td>\n",
       "      <td>1</td>\n",
       "      <td>@Alyssa_Milano They really were great pics, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12391</th>\n",
       "      <td>12403</td>\n",
       "      <td>1</td>\n",
       "      <td>*mischief look* soon ima TAKE over muwahahahah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70720</th>\n",
       "      <td>70732</td>\n",
       "      <td>0</td>\n",
       "      <td>@buutterr i heard the same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50487</th>\n",
       "      <td>50499</td>\n",
       "      <td>0</td>\n",
       "      <td>@ashalinggg what day's the 23rd? just 'cause I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98355</th>\n",
       "      <td>98367</td>\n",
       "      <td>0</td>\n",
       "      <td>@cooleycakeface when a nigga let his chick tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12785</th>\n",
       "      <td>12797</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;quot;Excuse me, you don't sleep with my girl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20443</th>\n",
       "      <td>20455</td>\n",
       "      <td>1</td>\n",
       "      <td>@0kat0 Hasn't started yet! They're just showin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85587</th>\n",
       "      <td>85599</td>\n",
       "      <td>1</td>\n",
       "      <td>@chrisfreeman I do...http://thephotogirl.tumbl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28600</th>\n",
       "      <td>28612</td>\n",
       "      <td>1</td>\n",
       "      <td>@abiiiiiiii hahaah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID  Sentiment                                      SentimentText\n",
       "25928   25940          0  @adil320 sending you hugs and encouragment tod...\n",
       "39572   39584          1  @Alyssa_Milano They really were great pics, la...\n",
       "12391   12403          1  *mischief look* soon ima TAKE over muwahahahah...\n",
       "70720   70732          0                        @buutterr i heard the same \n",
       "50487   50499          0  @ashalinggg what day's the 23rd? just 'cause I...\n",
       "98355   98367          0  @cooleycakeface when a nigga let his chick tal...\n",
       "12785   12797          1  &quot;Excuse me, you don't sleep with my girl ...\n",
       "20443   20455          1  @0kat0 Hasn't started yet! They're just showin...\n",
       "85587   85599          1  @chrisfreeman I do...http://thephotogirl.tumbl...\n",
       "28600   28612          1                                @abiiiiiiii hahaah "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas, numpy and the dataset, save it in a object called 'sentiment'\n",
    "# Your code here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Read file with param './data/train.csv', encoding='latin-1'\n",
    "sentiment = pd.read_csv('./data/train.csv', encoding='latin-1')\n",
    "\n",
    "# Let's check sentiment.head(10) and sample(10)\n",
    "# Your code here\n",
    "sentiment.head(10)\n",
    "sentiment.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the structure of a twit varies a lot between twit and twit. They have different lengths, letters, numbers, extrange characters, etc. \n",
    "\n",
    "It is also important to note that **a lot** of words are not correctly spelled, for example the word _\"Juuuuuuuuuuuuuuuuussssst\"_ or the word _\"sooo\"_\n",
    "\n",
    "This makes it hard to mesure how positive or negative are the words within the twits.\n",
    "\n",
    "So we need a way of scoring the words such that words that appear in positive twits have greater score that those that appear in negative twits.\n",
    "\n",
    "But first... how do we represent the twits as vectors we can input to our algorithm?\n",
    "\n",
    "### Bag of words\n",
    "\n",
    "One thing we could do to represent the twits as equal-sized vectors of numbers is the following:\n",
    "\n",
    "* Create a list (vocabulary) with all the unique words in the whole corpus of twits. \n",
    "* We construct a feature vector from each twit that contains the counts of how often each word occurs in the particular twit\n",
    "\n",
    "_Note that since the unique words in each twit represent only a small subset of all the words in the bag-of-words vocabulary, the feature vectors will mostly consist of zeros_\n",
    "\n",
    "Lets construct the bag of words. We will work with a smaller example for illustrative purposes, and at the end we will work with our real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "twits = [\n",
    "    'This is amazing!',\n",
    "    'ML is the best, yes it is',\n",
    "    'I am not sure about how this is going to end...'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import [CountVectorizer.](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) It'll help us to convert a collection of text documents to a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define an object of CountVectorizer() fit and transfom your twits into a 'bag'\n",
    "# Your code here\n",
    "vectorizer = CountVectorizer()\n",
    "bag = vectorizer.fit_transform(twits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about', 'am', 'amazing', 'best', 'end', 'going', 'how', 'is', 'it', 'ml', 'not', 'sure', 'the', 'this', 'to', 'yes']\n"
     ]
    }
   ],
   "source": [
    "# Find in document of CountVectorizer a function that show us list of feature names\n",
    "# Your code here\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from executing the preceding command, the vocabulary is stored in a Python array that maps the unique words to integer indices. Next, let's print the feature vectors that we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 2 1 1 0 0 1 0 0 1]\n",
      " [1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Call toarray() on your 'bag' to see the feature vectors\n",
    "# Your code here\n",
    "a = bag.toarray()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# What is the index of the word 'is' and how many times it occurs in all three twits?\n",
    "# Your answer here\n",
    "print(vectorizer.get_feature_names().index('is'))\n",
    "count = 0\n",
    "for i in range(len(a)):\n",
    "        count += a[i][7]\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each index position in the feature vectors corresponds to the integer values that are stored as dictionary items in the CountVectorizer vocabulary. For example, the first feature at index position 0 resembles the count of the word 'about' , which only occurs in the last document. These values in the feature vectors are also called the **raw term frequencies**: `tf(t,d )` —the number of times a term `t` occurs in a document `d`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How relevant are words? Term frequency-inverse document frequency\n",
    "\n",
    "We could use these raw term frequencies to score the words in our algorithm. There is a problem though: If a word is very frequent in _all_ documents, then it probably doesn't carry a lot of information. In order to tacke this problem we can use **term frequency-inverse document frequency**, which will reduce the score the more frequent the word is accross all twits. It is calculated like this:\n",
    "\n",
    "\\begin{equation*}\n",
    "tf-idf(t,d) = tf(t,d) ~ idf(t,d)\n",
    "\\end{equation*}\n",
    "\n",
    "_tf(t,d)_ is the raw term frequency descrived above. _idf(t,d)_ is the inverse document frequency, than can be calculated as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\log \\frac{n_d}{1+df\\left(d,t\\right)}\n",
    "\\end{equation*}\n",
    "\n",
    "where `n` is the total number of documents and _df(t,d)_ is the number of documents where the term `t` appears. \n",
    "\n",
    "The `1` addition in the denominator is just to avoid zero term for terms that appear in all documents, will not be entirely ignored. Ans the `log` ensures that low frequency term don't get too much weight.\n",
    "\n",
    "Fortunately for us `scikit-learn` does all those calculations for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit_transform() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-1cfa969e5e39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Feed the tf-idf transformer with our previously created Bag of Words using fit_transform()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtfidf_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit_transform() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "# Formatting the number to 2 digits after the decimal point by showing on this notebook\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Feed the tf-idf transformer with our previously created Bag of Words using fit_transform()\n",
    "# Your code here\n",
    "tfidf_vect = tfidf.fit_transform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now what is the weight of the word 'is' and 'amazing'?\n",
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String manipulation in Python\n",
    "\n",
    "One place where the Python language really shines is in the manipulation of strings. This section will cover some of Python's built-in string methods and formatting operations, before moving on to a quick guide to the extremely useful subject of regular expressions. Such string manipulation patterns come up often in the context of data science work\n",
    "\n",
    "### Formatting strings: Adjusting case\n",
    "\n",
    "Python makes it quite easy to adjust the case of a string. Here we'll look at the `upper()`, `lower()`, `capitalize()`, and `swapcase()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE QUICK BROWN FOX.\n",
      "the quick brown fox.\n",
      "The quick brown fox.\n",
      "ThE QuicK BrowN FoX.\n"
     ]
    }
   ],
   "source": [
    "fox = 'tHe qUICk bROWn fOx.'\n",
    "# Apply the functions above to `fox` and print out the results\n",
    "# Your code here\n",
    "print(fox.upper())\n",
    "print(fox.lower())\n",
    "print(fox.capitalize())\n",
    "print(fox.swapcase())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding and removing spaces\n",
    "\n",
    "Another common need is to remove spaces (or other characters) from the beginning or end of the string. The basic method of removing characters is the `strip()` method, which strips whitespace from the beginning and end of the line. To remove just space to the right or left, use `rstrip()` or `lstrip()` respectively.\n",
    "\n",
    "To remove characters other than spaces, you can pass the desired character to the `strip()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = '         this is the content         '\n",
    "\n",
    "# Apply strip(), rstrip(), lstrip() to 'line' and print the results out\n",
    "# Your code here\n",
    "print(line.strip())\n",
    "num = '00000000435'\n",
    "# Remove all of the zeros from num\n",
    "# Your code here\n",
    "print(num.lstrip('0'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding and replacing and splitting\n",
    "\n",
    "If you want to find occurrences of a certain character in a string, the `find()`, `index()` and `replace()` methods are the best built-in methods.\n",
    "\n",
    "`find()` and `index()` are very similar, in that they search for the first occurrence of a character or substring within a string, and return the index of the substring.\n",
    "\n",
    "The `split()` method is perhaps more useful; it finds all instances of the split-point and returns the substrings in between. The default is to split on any whitespace, returning a list of the individual words in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = 'the quick brown fox jumped over a lazy dog'\n",
    "\n",
    "# Find the index of 'fox' in 'line' using find() and index()\n",
    "# Your code here\n",
    "print(line.index('fox'))\n",
    "# Let's replace 'brown' with 'red'\n",
    "# Your code here\n",
    "print(line.replace(\"brown\", \"red\"))\n",
    "# List all words in 'line' and put them in an array\n",
    "# Your 1 line of code here\n",
    "print(line.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you would like to undo a `split()`, you can use the `join()` method, which returns a string built from a splitpoint and an iterable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'--'.join(['1', '2', '3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common pattern is to use the special character \"\\n\" (newline) to join together lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(['Rules in family:', '1. Your wife is always right.', '2. If she is wrong, check the first rule again.']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression\n",
    "\n",
    "In Python, regular expressions are supported by the `re` module.\n",
    "\n",
    "A regular expression (or RE) specifies a set of strings that matches it; the functions in this module let you check if a particular string matches a given regular expression (or if a given regular expression matches a particular string, which comes down to the same thing).\n",
    "\n",
    "Let's walk through some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_regex = '\\w+@\\w+\\.[a-z]{2}'\n",
    "text = \"To email Hai Minh, try minhdh@coderschool.vn or the older address haiminh101@yahoo.vn\"\n",
    "re.findall(email_regex, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing these email addresses with another string, perhaps to hide addresses in the output:\n",
    "re.sub(email_regex, '--@--.--', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following will match any lower-case vowel:\n",
    "re.split('[aeiou]', 'consequential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to extract from a document specific numerical codes that consist of a capital letter followed by a digit. You could do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('[A-Z][0-9]', '1043879, G2, H6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table lists a few of these characters that are commonly useful:\n",
    "\n",
    "| Character | Description | Character | Description |\n",
    "|------------|-----------|------------|-----------|\n",
    "| \"\\d\" | Match any digit   | \"\\D\" | Match any non-digit|\n",
    "| \"\\s\" | Match any whitespace   | \"\\S\" | Match any non-whitespace|\n",
    "| \"\\w\" | Match any alphanumeric char  | \"\\W\" | Match any non-alphanumeric char|\n",
    "\n",
    "| Character | Description | Example |\n",
    "|------------|-----------|------------|\n",
    "| ? | Match zero or one repetitions of preceding |  \"ab?\" matches \"a\" or \"ab\" |\n",
    "| * | Match zero or more repetitions of preceding | \"ab*\" matches \"a\", \"ab\", \"abb\", \"abbb\"... |\n",
    "| + | Match one or more repetitions of preceding |  \"ab+\" matches \"ab\", \"abb\", \"abbb\"... but not \"a\" |\n",
    "| {n} | Match n repetitions of preceding | \"ab{2}\" matches \"abb\" |\n",
    "| {m,n} | Match between m and n repetitions of preceding |  \"ab{2,3}\" matches \"abb\" or \"abbb\" |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Resources on Regular Expressions\n",
    "\n",
    "* [Python's re package Documentation](https://docs.python.org/3/library/re.html)\n",
    "* [Python's official regular expression HOWTO](https://docs.python.org/3/howto/regex.html)\n",
    "* [Mastering Regular Expressions (OReilly, 2006)](http://shop.oreilly.com/product/9780596528126.do)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data clean up\n",
    "\n",
    "### Removing stop words\n",
    "\n",
    "Now that we know how to format and score our input. Let's look at our **real** vocabulary. Specifically, the most common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'blue': 3, 'red': 2, 'green': 1})\n",
      "[('blue', 3), ('red', 2)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Example\n",
    "count = Counter()\n",
    "for word in ['red', 'blue', 'red', 'green', 'blue', 'blue']:\n",
    "    count[word] += 1\n",
    "print(count)\n",
    "print(count.most_common(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 32880),\n",
       " ('to', 28810),\n",
       " ('the', 28088),\n",
       " ('a', 21321),\n",
       " ('you', 21180),\n",
       " ('i', 16000),\n",
       " ('and', 14565),\n",
       " ('it', 12819),\n",
       " ('my', 12385),\n",
       " ('for', 12149),\n",
       " ('in', 11199),\n",
       " ('is', 11185),\n",
       " ('of', 10326),\n",
       " ('that', 9181),\n",
       " ('on', 9020),\n",
       " ('have', 8991),\n",
       " ('me', 8255),\n",
       " ('so', 7612),\n",
       " ('but', 7220),\n",
       " ('be', 7093)]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "# Let's apply the example above to count words in our SentimentText\n",
    "# Your code here\n",
    "sentiment.SentimentText\n",
    "for row in sentiment.SentimentText:\n",
    "    for word in row.split():\n",
    "        vocab[word] += 1\n",
    "        \n",
    "vocab.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the most common words are meaningless in terms of sentiment: _I, to, the, and_... they don't give any information on positiveness or negativeness. They're basically **noise** that can most probably be eliminated. These kind of words are called _stop words_, and it is a common practice to remove them when doing text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/trungdo/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 32880),\n",
       " (\"I'm\", 6416),\n",
       " ('like', 5086),\n",
       " ('-', 4922),\n",
       " ('get', 4864),\n",
       " ('u', 4194),\n",
       " ('good', 3953),\n",
       " ('love', 3494),\n",
       " ('know', 3472),\n",
       " ('go', 2990),\n",
       " ('see', 2868),\n",
       " ('one', 2787),\n",
       " ('got', 2775),\n",
       " ('think', 2613),\n",
       " ('&amp;', 2556),\n",
       " ('lol', 2419),\n",
       " ('going', 2396),\n",
       " ('really', 2287),\n",
       " ('im', 2200),\n",
       " ('day', 2195)]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "vocab_reduced = Counter()\n",
    "# Go through all of the items of vocab using vocab.items() and pick only words that are not in 'stop' \n",
    "# and save them in vocab_reduced\n",
    "# Your code here\n",
    "for word, c in vocab.items():\n",
    "    if not word in stop:\n",
    "        vocab_reduced[word] = c\n",
    "\n",
    "vocab_reduced.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks better, only in the 20 most common words we already see words that make sense: good, love, really... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing special characters and \"trash\"\n",
    "\n",
    "If you look closer, you'll see that we're also taking into consideration punctuation signs ('-', ',', etc) and other html tags like `&amp`. We can definitely remove them for the sentiment analysis, but we will try to keep the emoticons, since those _do_ have a sentiment load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "def preprocessor(text):\n",
    "    \"\"\" Return a cleaned version of text\n",
    "    \"\"\"\n",
    "    # Remove HTML markup\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    # Save emoticons for later appending\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    # Remove any non-word character and append the emoticons,\n",
    "    # removing the nose character for standarization. Convert to lower case\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Create some random texts for testing the function preprocessor()\n",
    "print(preprocessor(''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost ready! There is another trick we can use to reduce our vocabulary and consolidate words. If you think about it, words like: love, loving, etc. _Could_ express the same positivity. If that was the case, we would be  having two words in our vocabulary when we could have only one: lov. This process of reducing a word to its root is called **stemming**.\n",
    "\n",
    "We also need a _tokenizer_ to break down our twits in individual words. We will implement two tokenizers, a regular one and one that does steaming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'there,', 'I', 'am', 'loving', 'this,', 'like', 'with', 'a', 'lot', 'of', 'love']\n",
      "['Hi', 'there,', 'I', 'am', 'love', 'this,', 'like', 'with', 'a', 'lot', 'of', 'love']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# write a function called `tokenizer()` that split a text into list of words\n",
    "def tokenizer(text):\n",
    "    token = [] \n",
    "    # Your code here\n",
    "    token = text.split()\n",
    "    return token\n",
    "\n",
    "\n",
    "# write a function named `tokenizer_porter()` that split a text into list of words and apply stemming technic\n",
    "# Hint: porter.stem(word)\n",
    "def tokenizer_porter(text):\n",
    "    token = []\n",
    "    # Your code here\n",
    "    token = [porter.stem(word) for word in text.split()]\n",
    "    \n",
    "    return token\n",
    "\n",
    "# Testing\n",
    "print(tokenizer('Hi there, I am loving this, like with a lot of love'))\n",
    "print(tokenizer_porter('Hi there, I am loving this, like with a lot of love'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Logistic Regression\n",
    "\n",
    "We are finally ready to train our algorythm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset in train and test\n",
    "# Your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = sentiment.SentimentText\n",
    "y = sentiment.Sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:286: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'ha', 'hi', 'onc', 'onli', 'ourselv', 'themselv', 'thi', 'veri', 'wa', 'whi', 'yourselv'] not in stop_words.\n",
      "  sorted(inconsistent))\n",
      "/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2',\n",
       "        preprocessor=<function prepr...e, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=stop,\n",
    "                        tokenizer=tokenizer_porter,\n",
    "                        preprocessor=preprocessor)\n",
    "\n",
    "# A pipeline is what chains several steps together, once the initial exploration is done. \n",
    "# For example, some codes are meant to transform features — normalise numericals, or turn text into vectors, \n",
    "# or fill up missing data, they are transformers; other codes are meant to predict variables by fitting an algorithm,\n",
    "# they are estimators. Pipeline chains all these together which can then be applied to training data\n",
    "clf = Pipeline([('vect', tfidf),\n",
    "                ('clf', LogisticRegression(random_state=0))])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70     13151\n",
      "           1       0.76      0.82      0.79     16846\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     29997\n",
      "   macro avg       0.75      0.74      0.75     29997\n",
      "weighted avg       0.75      0.75      0.75     29997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Now apply those above metrics to evaluate your model\n",
    "# Your code here\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run some tests :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is really bad --> Positive, Negative = [0.96 0.04]\n",
      "I love this! --> Positive, Negative = [0.08 0.92]\n",
      ":) --> Positive, Negative = [0.38 0.62]\n"
     ]
    }
   ],
   "source": [
    "twits = [\n",
    "    \"This is really bad\",\n",
    "    \"I love this!\",\n",
    "    \":)\",\n",
    "]\n",
    "\n",
    "preds = clf.predict_proba(twits)\n",
    "\n",
    "for i in range(len(twits)):\n",
    "    print(f'{twits[i]} --> Positive, Negative = {preds[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we would like to use the classifier in another place, or just not train it again and again everytime, we can save the model in a pickle file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "pickle.dump(clf, open(os.path.join('data', 'logisticRegression.pkl'), 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And you're done! I hope you liked this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
